# Private Speech-to-Text Configuration

# Audio sample rate for processing (Hz)
# Both Vosk and Whisper work well with 16000 Hz
sample_rate = 16000

# Audio gain/amplification (1.0 = no change, 2.0 = double, 3.0 = triple)
# Increase if recordings are too quiet (try 2.0, 3.0, or higher)
# Decrease if recordings are distorted (try 0.5)
audio_gain = 8

# Directory where recordings and transcriptions will be saved
# Can be absolute path (e.g., "/home/user/recordings") or relative (e.g., "./recordings")
output_directory = "./recordings"

# Path to Vosk model directory for REAL-TIME streaming recognition
# Vosk is designed for streaming and provides instant, low-latency feedback during recording
# Download from: https://alphacephei.com/vosk/models
# Recommended: vosk-model-small-en-us-0.15 (40 MB) - good balance of speed and accuracy
# Alternative: vosk-model-en-us-0.22 (1.8 GB) - better accuracy, higher CPU usage   
vosk_model_path = "./models/vosk-model-small-en-us-0.15"

# Path to Whisper model file for ACCURATE post-processing transcription
# Whisper provides the highest quality transcription after recording stops
# Download from: https://huggingface.co/ggerganov/whisper.cpp
# Recommended: ggml-small.en.bin (460 MB) - high accuracy
# Alternative: ggml-medium.en.bin (1.5 GB) - best accuracy, slower
whisper_model_path_accurate = "./models/ggml-small.en.bin"

# Enable accurate recognition with Whisper after recording stops
# Set to false if you only want real-time Vosk transcription
enable_accurate_recognition = true

# Enable Ollama summary generation after recording
ollama_enabled = false

# Ollama server host (include scheme and port if needed)
ollama_host = "http://diablo:11434"

# Ollama model name
ollama_model = "llama3.2"

# Prompt prefix for summarization
ollama_prompt = "Summarize the following transcript in concise bullet points."

# Suffix for summary file names (e.g. 2026-02-04_12-00-00_summary.txt)
summary_suffix = "_summary"

# Timeout for Ollama requests (seconds)
ollama_timeout_secs = 60

