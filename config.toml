# Private Speech-to-Text Configuration

# Audio sample rate for processing (Hz)
# Defaults to 16000 if omitted (Whisper works best at 16kHz).
# You can remove the next line to use the default.
# sample_rate = 16000

# Audio gain/amplification (1.0 = no change, 2.0 = double, 3.0 = triple)
# Increase if recordings are too quiet (try 2.0, 3.0, or higher)
# Decrease if recordings are distorted (try 0.5)
audio_gain = 8

# Directory where recordings and transcriptions will be saved
# Can be absolute path (e.g., "/home/user/recordings") or relative (e.g., "./recordings")
output_directory = "./recordings"

# Real-time recognition engine selection
# "vosk"        - legacy Vosk engine (fast, requires a Vosk model)
# "sherpa-onnx" - Sherpa ONNX engine (higher quality, requires
#                  --features sherpa-engine and four model files)
# The shipped example config defaults to "sherpa-onnx".  If you
# omit this field entirely when loading config, the code will fall
# back to "vosk" (so a minimal config works without requiring
# sherpa).  When using "sherpa-onnx" you can omit `vosk_model_path`;
# the field is only required for the Vosk engine.
realtime_engine = "sherpa-onnx"

# Path to sherpa-onnx streaming Zipformer model files (used when realtime_engine = "sherpa-onnx")
# Each file must be specified individually because model archives use versioned filenames.
# Build with: cargo build --features sherpa-engine
#
# Download English model (int8, ~70 MB encoder) on Windows:
#   Invoke-WebRequest -Uri "https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-en-2023-06-26.tar.bz2" -OutFile model.tar.bz2
#   tar xf model.tar.bz2   (requires tar, available in Windows 10+)
#   move sherpa-onnx-streaming-zipformer-en-2023-06-26 .\models\
#
# Browse all models:
#   https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html
#
sherpa_encoder = "./models/sherpa-onnx/sherpa-onnx-streaming-zipformer-en-2023-06-26/encoder-epoch-99-avg-1-chunk-16-left-128.int8.onnx"
sherpa_decoder = "./models/sherpa-onnx/sherpa-onnx-streaming-zipformer-en-2023-06-26/decoder-epoch-99-avg-1-chunk-16-left-128.onnx"
sherpa_joiner  = "./models/sherpa-onnx/sherpa-onnx-streaming-zipformer-en-2023-06-26/joiner-epoch-99-avg-1-chunk-16-left-128.int8.onnx"
sherpa_tokens  = "./models/sherpa-onnx/sherpa-onnx-streaming-zipformer-en-2023-06-26/tokens.txt"

# Path to Whisper model file for ACCURATE post-processing transcription
# Whisper provides the highest quality transcription after recording stops
# Download from: https://huggingface.co/ggerganov/whisper.cpp
# Recommended: ggml-small.en.bin (460 MB) - high accuracy
# Alternative: ggml-medium.en.bin (1.5 GB) - best accuracy, slower
whisper_model_path_accurate = "./models/whisper/ggml-small.en.bin"

# Enable accurate recognition with Whisper after recording stops
# Set to false if you only want real-time transcription
enable_accurate_recognition = true

# Enable Ollama summary generation after recording
ollama_enabled = false

# Ollama server host (include scheme and port if needed)
ollama_host = "http://localhost:11434"

# Ollama model name
ollama_model = "llama3.2"

# Prompt prefix for summarization
ollama_prompt = "Summarize the following transcript in concise bullet points."

# Suffix for summary file names (e.g. 2026-02-04_12-00-00_summary.txt)
summary_suffix = "_summary"

# Timeout for Ollama requests (seconds)
ollama_timeout_secs = 60

